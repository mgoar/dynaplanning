[LearningModel]++->[AbstractStrategy]
[Incentiver]<>-considers>[AbstractStrategy]
[DynaAgentPlus]<>-1>[LearningModel]
[StackelbergInstance]<>1-*>[AbstractAgent]

// Composition
[AbstractAgent]++->[DynaAgentPlus]
[AbstractStrategy]++->[StackelbergStrategy]
[AbstractStrategy]++->[SelfishStrategy]
[AbstractInstance]++->[StackelbergInstance]

// Classes
[LearningModel|+model: Dict((Edge,AbstractStrategy,Edge)
(Edge,Float64));+incentiver:Incentiver|LearningModel()]

[Incentiver|+strategy_followed: AbstractStrategy|Incentiver();Incentiver(AbstractStrategy)]

[<<interface>>AbstractStrategy|]
[StackelbergStrategy|+strategy: Array(Float64,1)| StackelbergStrategy()]

[SelfishStrategy|+strategy: Array(Float64,1)| SelfishStrategy()]

[<<interface>>;AbstractAgent]

[DynaAgentPlus|+path:Array(Edge,1) Array(Float64,1);+state:Edge;+actions:Array(Edge,1);+gamma:Float32;+alpha:Float32;+epsilon:Float32;+episodes:Int64;+tau:Int64;+kappa:Float32;+theta:Float32;+queue:PriorityQueue((Edge,AbstractStrategy),AbstractStrategy);+predecessors(Array((Int64,Edge),AbstractStrategy,1));+strategy:AbstractStrategy;+time:Int64| DynaAgentPlus()]

[<<interface>>;AbstractInstance]

[StackelbergInstance|+network:SimpleWeightedDiGraph;+beta:Float32;+agents:Array(DynaAgentPlus,1)| StackelbergInstance()]